# Features (unorganized)

## Cluster creation

### valkey.conf

Cluster settings
```ini
cluster-enabled yes
cluster-require-full-coverage no
cluster-node-timeout 10000
cluster-config-file /data/nodes.conf
cluster-migration-barrier 1
```

TLS settings
```ini
tls-port 6379
port 0
tls-cert-file /etc/valkey-cluster/tls/server.crt
tls-key-file /etc/valkey-cluster/tls/server.key
tls-ca-cert-file /etc/valkey-cluster/tls/ca_bundle.pem
tls-auth-clients yes
tls-cluster yes
tls-replication yes
```

```sh
valkey-cli --cluster create --cluster-replicas 1 node-0.ns:6379 ... node-n.ns:6379
```

## CR Changes Reconciliation
TBD

## **Operator** recovery and resources reconciliation from restart/scale 0
TBD

## Resources identification

Mark all created kubernetes resources (statefulsets, configmaps, secrets, pvcs, svcs, pdbs etc) with an annotation, to clearly link them to the `ValkeyCluster`. Like
```yaml
metadata:
  annotations:
    valkey.io/cr: valkey-poc    # name of the ValkeyCluster
    valkey.io/locked: "true"    # maybe...
  ownerReferences:
    # etc
```

On all pods, whane created, `PATCH` a label for potential pod selection. Format will be "{cr-name}-{cr-type}-pod-{pod-no}"
```yaml
metadata:
  labels:
    valkey-pod-extra-selector: valkey-poc-cluster-pod-0
```

All created CRs must have set correct `ownerReferences`.

## Unbound Valkey cluster from **operator**

If the user wishes to take control over Valkey cluster, it will be allowed to remove `valkey.io/cr: valkey-poc` from `statefulset`. After doing this, the operator will perform the following:
- clear all other annotations from resources
- will clear all statuses from `ValkeyClusterStatus` and will change to
```yaml
status:
  phase: Unbound
```
**TBD:** what to do and how, if user wants it back

## Validation Webhooks

In order to distinguish changes self vs others, **operator** generates a unique token per update. The webhook maintains a short-lived cache of valid tokens. Once used, the token is invalidated.

```yaml
metadata:
  annotations:
    valkey.io/update-token: "abc123"
```

All other changes are rejected. Exceptions are pods, for `delete`.

## Operator - Sidecar communication

**Operator** is mostly idle, the **sidecar’s** heartbeat is low-frequency and lightweight. The communication will be
- **Sidecar** initiated - Heartbits or major events: HTTP/1.1. Major events can be Valkey failed, someone deleted the pod
- **Operator** initiated - rest of communication: gRPC - only **orchestrator** open channels to needed **sidecars** when orchestration is triggered. Even use short-lived gRPC streams if needed.

## TLS

If `externalCerts` is provided in `ValkeyClusterTls`, it will be validated in **init-container** or **sidecar**.  
If not, using the one in `ValkeyCertificateBundle`, there will be generated certs with validity from `clientCertValidity`.  
In any case, they will be stored in secret from `tlsSecretName` and mounted in pods.

If certs are autogenerated, there will be a cron job that will regenerate the certs on demand.  
They will be updated in secret from `tlsSecretName` and mounted in pods.

The secrets can be for server, init-container (should we?), valkey sidecar, or exporter. The process is the same, with the big difference that redis and exporter must be restarted. The certificates are from different volumes (as the sources are different) and stored in different files.

When the secret is changed, the following will happen:
Phase 1
1. **Sidecar** will detect change
2. **Sidecar** will check the new certs for CA(s), intermediate and server/client
3. **Sidecar** announce the **operator**

Phase 2
1. **Operator** changes the status of nodes in CRs
2. **Operator** waits for all **sidecars** to respond
3. **Operator** will wait another 1m (5m? 10m?) for other certificates to change. If there are overlapping certificate changes (say "in the same time", are chnaged valkey, sidecar), it will wait for all of them

Phase 3
1. _(if valkey or exporter)_ **Operator** will perform a _Rolling restart_
2. _(if sidecar)_ **Operator** will ask **sidecar** to change its certificates

### Error handling
If any errors, the cluster state changes to `Error` (TBD and rest), `PDB` to 100%

**Important**, as Valkey uses a basic mTLS, the certificates must follow theese rules
- Valkey uses a server certificate, with `serverAuth`
- Clients (**Sidecar**, Exporter) use a client certificate, with `clientAuth`
- all of them are signed by the same internal CA (or intermediates), but have distinct keys and purposes
- always provide bunlded CA if changed. Othervise, the cluster will break

TBD - status in CRs

## mTLS

**Operator** generates a root CA on install, saved in ValkeyCA. For each Valkey cluster, it generates an intermediate CA, saved in `ValkeyCertificateBundle`. The mTLS certificates are mounted from secrets in containers as volumes. Maybe must mount CA in containers in ca-bundle (in valkey no, in sidecar maybe). On cert change, **Sidecar** will reload and use it. **Operator** will accept a period of time (1m? 1h?) the older cert. After all sidecars are switched, will unload it from memory and *(TBD)* will clean ValkeyCertificateBinding of deprecated.

**AuthN/AuthZ:** use SPIFFE-style SANs to authorize requests (e.g. only sidecars with CN `valkey-poc-sidecar` can respond).

Protobuf contracts with versioning.

TBD - status in CRs

## Rolling restarts

When an **operator** rolling restart is triggered, the **operator** doesn't simulate a kubernetes one, as in it will not restart pods from last to first, but will first restart all replicas (slaves), then will switch all primaries to replicas, and then will restart previous primaries (now replicas).

> **Important:** all actions are taking place only if the cluster is healthy. The check is before and after all (sub)phases

**Operator** loads cluster state from CR. It is mainly to get the list of primaries and replicas.

Phase 1 - replicas restart  

Subphase 1 - preparation - all steps are in paralel:
1. **Operator** opens a channel to **sidecar** in replica pod
2. **Operator** announces the intent of delete
3. **Sidecar** makes a last verification that is a replica and aknoledges. If not, the entire process is restarted.
4. **Sidecar** will not block/delay the restart (usage of `lifecycle.prestop:`)

Subpahse 2 - aknowledges await - here **operator** waits for all replicas' okays.  

Subphase 3 - restarts - all steps are sequential:
1. **Operator** deletes the pod
2. **Operator** waits for the pods to be online + sidecar
3. *TBD* what to do with DNS TTL issue. should it wait after the last one the duration of TTL?

Phase 2 - primaries/replicas switch - all steps are sequential. this is a moment of disrupture
1. **Operator** chooses a replica and opens a channel
2. **Operator** asks **sidecar** to perform `CLUSTER FAILOVER`
3. **Operator** waits for new status from **sidecar**

Phase 3 - old primaries (now replicas) restart  
Same steps from Phase 1

### User triggered via command/api/etc

When user runs `kubectl rollout restart statefulset` (or eq), kubernetes sets a new `spec.template.metadata.annotations["kubectl.kubernetes.io/restartedAt"]` timestamp on the StatefulSet. Normally, that change causes the StatefulSet controller to recreate pods; due to `updateStrategy: type: OnDelete`, nothing will happen.

**Operator** will detect this change and will trigger a rollout restart.

## Pods deletion blocking

TBD - to make it more clear, also to explain what to implement and how (from ways of blocking). sigterm trap for sidecar is missing (do we need this if valkey-preStop.sh exists?). and operator promoting primaries. and DNS issue with headless svc. and status in CRs is missing

In order to block/delay pod deletion, the following will be implemented:
| What | Where | Comments |
|------|-------|----------|
| `updateStrategy.type: OnDelete` | Statefulset | it will make manual pod delete mandatory in order to change anything |
| `lifecycle.preStop.exec` | Containers | on all of them. Upon pod delete, the `valkey-preStop.sh` will be executed |

The `valkey-preStop.sh` file is watched for by **sidecar**
- (bound cluster) if there were no messages from **operator**, the **sidecar** will signal back to operator that an unexpected delete is taking place. If primary node, the **operator** will apply Phase 2 from _Rolling restarts_, and will signal **sidecar** to continue with pod delete, **sidecar** will delete the file `/tmp/pod-deleted-signal.txt`
- (bound cluster) if it is a planned delete, the sidecar will just delete the `/tmp/pod-deleted-signal.txt` file
- (unbound cluster) **sidecar** will check if node is a primary, and if so, it will contact directly a replica and execute `CLUSTER FAILOVER` and waits for its change. After, it will delete the file `/tmp/pod-deleted-signal.txt`

### valkey-preStop.sh script
```sh
#!/bin/sh

# Create the signal file
touch /tmp/pod-deleted-signal.txt
echo "Waiting for /tmp/pod-deleted-signal.txt to be deleted..."

# Loop until the file is gone
while [ -f /tmp/pod-deleted-signal.txt ]; do
  sleep 1
done

echo "Signal file deleted. Exiting."
```

## ACL creation and rotation

### Pod startup - **init-container**
Upon pod start, the following happens:
1. **Init container** checks the file `acl-definitions.yaml` from `/etc/valkey-cluster/acl`
2. If the file is ok, **init container** will prepare the `/etc/valkey-operator-sidecar/tranzit/users.acl` file, will create `/etc/valkey-cluster/valkey-configs/valkey.conf` file from `/etc/valkey-cluster/base-config/valkey-base.conf` and will add in it
```ini
user __valkey_admin_name__ on >__valkey_admin_pass__ +@all ~*
user __primary_replication_user__ on >__primary_replication_pass__ +@all ~*
  
masteruser __primary_replication_user__
masterauth __primary_replication_pass__

aclfile /etc/valkey/acl/users.acl
```
3. **init-container** will create file `pwd-file.json` in `/etc/valkey-cluster/exporter-configs`. More in _oliver006/redis_exporter_ section, in _Vars_

#### Errors mitigations:
_(Bound cluster)_ If any of the following (and check for all)
- the file `/etc/valkey-cluster/acl/acl-definitions.yaml` is corrupt
- missing important info (nodes `valkey-user`, `replication-user`, (based on settings) `exporter-user` and their fields)
- user for replication has changed or its password does not contain the actual one

there will be the following steps:
- **init-container** signal all errors to **operator** and waits
- **operator** will change cluster status in CR to `Error` (TBD and more)
- **operator** will change `PDB` to 100%
- **operator** will ask a another running pod to provide its running ACL
- **operator** will provide the ACL to the **init-container**
- **init-container** will create the ACL file

_(Unbound cluster)_ log the errors, wait for 30s (?) and restart

> **Why restart if _Unbound cluster_ :** there is no mTLS available. There is no way to securely connect to another **sidecar** and retreive the ACL. Also, **sidecars** do not listen in this case

### Pod startup, **sidecar** checks
After the pod starts, the **sidecar** will connect to Valkey container and will check the ACL. If ACL consists in only those two users (3 including `default`?) and there should be more, the following will happen:
- for each additional users in `acl-definitions.yaml`, it will try to create them
- for each success, it will add the line in `users.acl`
- for each error, it will report back to **operator**, that will change cluster status in CR to `Error` (TBD and more)

### Secret rotation
_(Bound clusters)_ When change in secret is detected, the following happens:

Phase 1
1. **Sidecar** checks the file `acl-definitions.yaml` from `/etc/valkey-cluster/acl` (the checks from above, done by **init-container**)
2. If the file is ok, **sidecar** will prepare the `/etc/valkey-operator-sidecar/tranzit/users.acl.new` file
3. **Sidecar** will backup actual ACL file in `/etc/valkey-operator-sidecar/tranzit/users.acl.backup`
4. **Sidecar** will get current node type (primary/replica) and will signal **operator** new acl received (node type, acl sha256)

Phase 2
1. **Operator**, on first announcement, will change `PDB` to `100%`
2. **Operator** waits for all signals from **sidecars**. And a timeout here? 1m? 2m?
3. If all have same sha256, will continue. If not... what? beside a nice status in ACL CR?

Phase 3 (sequential)
1. **Operator** opens channel with all primaries and ask for ACL change
2. **sidecar** copy the new ACL file in its place and will run `ACL LOAD` in Valkey
3. _(only if `valkey-admin` changed)_ **Sidecar** change `valkey.conf` and `user` counterpart
4. _(only if `masterauth` changed)_ **Sidecar** change pass for in `valkey.conf` and `user` counterpart
5. _(only if `exporter-user` changed)_ **Sidecar** recreates file `pwd-file.json` and call `curl -X POST http://localhost:9121/-/reload`
6. **Sidecar** reports status back to **operator** status ok
7. ~~**Sidecar** saves the `acl-definitions.yaml` file in `/opt/valkey-operator-sidecar/tranzit`~~

Phase 4
1. **Operator** opens channel with all replicas and ask for ACL change
2. **sidecar** copy the new ACL file in its place and  will run `ACL LOAD` in Valkey
3. _(only if `valkey-admin` changed)_ **Sidecar** change `valkey.conf` and `user` counterpart; run `CONFIG SET masterauth newpass`
4. _(only if `masterauth` changed)_ **Sidecar** change pass for in `valkey.conf` and `user` counterpart
5. _(only if `exporter-user` changed)_ **Sidecar** recreates file `pwd-file.json` and call `curl -X POST http://localhost:9121/-/reload`
6. **Sidecar** reports status back to **operator** status ok
7. ~~**Sidecar** saves the `acl-definitions.yaml` file in `/opt/valkey-operator-sidecar/tranzit`~~

Phase 5
1. **Operator** changes back `PDB` to `N-1`

_(Unbound cluster)_ There will be the following steps:
Phase 1 (from above)
1. **Sidecar** checks the file `acl-definitions.yaml` from `/etc/valkey-cluster/acl` (the checks from above, done by **init-container**)
2. If the file is ok, **sidecar** will prepare the `/etc/valkey-operator-sidecar/tranzit/users.acl.new` file
3. **Sidecar** will backup actual ACL file in `/etc/valkey-operator-sidecar/tranzit/users.acl.backup`

Phase 4
1. ~~**Operator** opens channel with all replicas and ask for ACL change~~
2. **sidecar** copy the new ACL file in its place and  will run `ACL LOAD` in Valkey
3. _(only if `valkey-admin` changed)_ **Sidecar** change `valkey.conf` and `user` counterpart; run `CONFIG SET masterauth newpass` (only if replica)
4. _(only if `masterauth` changed)_ **Sidecar** change pass for in `valkey.conf` and `user` counterpart
5. _(only if `exporter-user` changed)_ **Sidecar** recreates file `pwd-file.json` and call `curl -X POST http://localhost:9121/-/reload`

_end of secret rotation_

> **Hint:** a user can have multiple passwords in acl file. Also, test the ACL before making it permanent

#### Errors mitigations:

_(Bound cluster)_ In Phase 3, if there are errors (and normally it should happen only in first attempt), the following will happen:
- **Sidecar** will signal this to **operator**
- **Operator** will change CR status to `Error` (TBD and more), `PDB` will remain 100%
- **Sidecar** will restore ACL backup with `ACL LOAD`

_(Unbound cluster)_ Sidecar will clearly log the errors and will restore the ACL backup

> **Important** if we have failures here, it is a make or break. It can render the cluster unusable on restart.

## Deferred executions

There are cases when one object depends on another. Use Indexing for Reverse Lookup: with [controller-runtime](https://pkg.go.dev/sigs.k8s.io/controller-runtime), index the CRs by the Secrets they reference:

```go
mgr.GetFieldIndexer().IndexField(&ValkeyClusterAcl{}, "spec.secrets.secretName", func(obj client.Object) []string {
    return []string{obj.(*ValkeyClusterAcl).Spec.Secrets.SecretName}
})
```
Then, when a Secret changes, list all CRs that reference it:

```go
var aclList ValkeyClusterAclList
r.List(ctx, &aclList, client.MatchingFields{"spec.secrets.secretName": secret.Name})
```

The reconcile loop should:
- check if the Secret exists and is complete
- if not, set `status.phase`: `WaitingForSecret` and requeue
- if yes, proceed with work and update `status.phase`: `Applied`

Practicly, we have the following rules
1. When a CR changes, reconcile it
2. When a Secret changes, reconcile all CRs that reference it
3. Use Status to Track Progress
```yaml
status:
  phase: WaitingForSecret
  lastChecked: 2025-09-07T19:17:00Z
  missingKeys:
    - valkey-user-pass
```

Actual Known Deps:
| Who | DependsOn | Why/What |
|-----|-----------|----------|
| ValkeyCluster | ValkeyCertificateBundle | Intermediate CA for mTLS (and TLS) |
| ValkeyCluster | ValkeyCertificateBinding | Certs for mTLS (and TLS) |
| ValkeyCluster | ValkeyClusterAcl | Certs for mTLS (and TLS) |
| ValkeyCertificateBundle | ValkeyCertificateCA | Operator CA |
| ValkeyCertificateBundle | Secret | the secret that holds the intermediate certs |
| ValkeyCertificateBinding | ValkeyCertificateBundle | the issuer for certs |
| ValkeyCertificateBinding | Secrets | the secrets that hold the certs for mTLS (and TLS) |
| ValkeyClusterAcl | Secret | the secret that holds the ACL definitions |

## Others

**Status in CRs** - to reflect sidecar executions/Valkey cluster states  
**CRDs versioning** - as much as possible, do not change anything, add (with defaults)  
**Observability** - metrics (Prometheus), logging (structured)  
**Valkey /data** - accesible also from sidecar  
**Valkey /tmp** - common between containers


## To be added

**Certificate Authority (CA):** The CA used for mTLS can be either internally generated or externally provided (eg, via Vault, cert-manager, or a preloaded Secret). This flexibility allows alignment with different compliance and operational models.

**mTLS Intermediate & Certificates:** The operator issues intermediate certificates for mTLS between itself and the sidecar. These certificates are scoped per Valkey cluster and stored securely in Kubernetes Secrets. Rotation is automated and tracked via custom resources (ValkeyCertificateBundle), ensuring lifecycle observability.

**Init Container Bootstrapping:** An init container is responsible for preparing the runtime environment for both Valkey and its sidecar. It handles certificate retrieval, identity configuration, and role assignment, ensuring that each pod starts with the correct security context.

**AuthN/AuthZ via SPIFFE-style SANs:** Identity validation is enforced using SPIFFE-style SANs embedded in certificates. The operator and sidecar mutually verify each other's identities, with contextual checks (e.g., DNS, IP, cluster membership) to prevent impersonation and ensure secure coordination.

**Unbound Cluster Mode:** For high-security or air-gapped environments, the operator supports a “detached” mode. In this configuration:
- the Valkey cluster is scaffolded and handed off.
- sidecars remain but become opaque—no mTLS or coordination required.
- certificate rotation is relying on external secrets and operator-driven lifecycle management is disabled